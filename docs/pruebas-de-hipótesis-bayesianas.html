<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 13 Pruebas de hipótesis bayesianas | Notas Curso de Estadística (Parte I)</title>
  <meta name="description" content="Capítulo 13 Pruebas de hipótesis bayesianas | Notas Curso de Estadística (Parte I)" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 13 Pruebas de hipótesis bayesianas | Notas Curso de Estadística (Parte I)" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 13 Pruebas de hipótesis bayesianas | Notas Curso de Estadística (Parte I)" />
  
  
  

<meta name="author" content="Maikol Solís" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="prueba-de-comparación-de-medias-en-2-poblaciones.html"/>
<link rel="next" href="bondad-de-ajuste.html"/>
<script src="libs/header-attrs-2.1/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Curso de Estadística</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introducción</a></li>
<li class="chapter" data-level="2" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html"><i class="fa fa-check"></i><b>2</b> Inferencia estadística</a>
<ul>
<li class="chapter" data-level="2.1" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#ejemplo"><i class="fa fa-check"></i><b>2.1</b> Ejemplo</a></li>
<li class="chapter" data-level="2.2" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#modelo-estadístico"><i class="fa fa-check"></i><b>2.2</b> Modelo estadístico</a></li>
<li class="chapter" data-level="2.3" data-path="inferencia-estadística.html"><a href="inferencia-estadística.html#estadístico"><i class="fa fa-check"></i><b>2.3</b> Estadístico</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><i class="fa fa-check"></i><b>3</b> Densidades previas conjugadas y estimadores de Bayes</a>
<ul>
<li class="chapter" data-level="3.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-previa-distribución-a-priori"><i class="fa fa-check"></i><b>3.1</b> Distribución previa (distribución a priori)</a></li>
<li class="chapter" data-level="3.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#densidad-posterior"><i class="fa fa-check"></i><b>3.2</b> Densidad posterior</a></li>
<li class="chapter" data-level="3.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#proceso-de-modelación-de-parámetros."><i class="fa fa-check"></i><b>3.3</b> Proceso de modelación de parámetros.</a></li>
<li class="chapter" data-level="3.4" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-verosimilitud"><i class="fa fa-check"></i><b>3.4</b> Función de verosimilitud</a></li>
<li class="chapter" data-level="3.5" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#familias-conjugadas"><i class="fa fa-check"></i><b>3.5</b> Familias conjugadas</a></li>
<li class="chapter" data-level="3.6" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#densidades-previas-impropias"><i class="fa fa-check"></i><b>3.6</b> Densidades previas impropias</a></li>
<li class="chapter" data-level="3.7" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#funciones-de-pérdida"><i class="fa fa-check"></i><b>3.7</b> Funciones de pérdida</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-pérdida-cuadrática"><i class="fa fa-check"></i><b>3.7.1</b> Función de pérdida cuadrática</a></li>
<li class="chapter" data-level="3.7.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#función-de-pérdida-absoluta"><i class="fa fa-check"></i><b>3.7.2</b> Función de pérdida absoluta</a></li>
<li class="chapter" data-level="3.7.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#otras-funciones-de-pérdida"><i class="fa fa-check"></i><b>3.7.3</b> Otras funciones de pérdida</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#efecto-de-muestras-grandes"><i class="fa fa-check"></i><b>3.8</b> Efecto de muestras grandes</a></li>
<li class="chapter" data-level="3.9" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#consistencia"><i class="fa fa-check"></i><b>3.9</b> Consistencia</a></li>
<li class="chapter" data-level="3.10" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#laboratorio"><i class="fa fa-check"></i><b>3.10</b> Laboratorio</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-previa"><i class="fa fa-check"></i><b>3.10.1</b> Distribución previa</a></li>
<li class="chapter" data-level="3.10.2" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-conjunta"><i class="fa fa-check"></i><b>3.10.2</b> Distribución conjunta</a></li>
<li class="chapter" data-level="3.10.3" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#distribución-posterior"><i class="fa fa-check"></i><b>3.10.3</b> Distribución posterior</a></li>
<li class="chapter" data-level="3.10.4" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#agregando-nuevos-datos"><i class="fa fa-check"></i><b>3.10.4</b> Agregando nuevos datos</a></li>
<li class="chapter" data-level="3.10.5" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#familias-conjugadas-normales"><i class="fa fa-check"></i><b>3.10.5</b> Familias conjugadas normales</a></li>
<li class="chapter" data-level="3.10.6" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#funciones-de-pérdida-1"><i class="fa fa-check"></i><b>3.10.6</b> Funciones de pérdida</a></li>
<li class="chapter" data-level="3.10.7" data-path="densidades-previas-conjugadas-y-estimadores-de-bayes.html"><a href="densidades-previas-conjugadas-y-estimadores-de-bayes.html#caso-concreto"><i class="fa fa-check"></i><b>3.10.7</b> Caso concreto</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html"><i class="fa fa-check"></i><b>4</b> Estimación por máxima verosimilitud</a>
<ul>
<li class="chapter" data-level="4.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#propiedades-del-mle"><i class="fa fa-check"></i><b>4.1</b> Propiedades del MLE</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#propiedad-de-invarianza"><i class="fa fa-check"></i><b>4.1.1</b> Propiedad de invarianza</a></li>
<li class="chapter" data-level="4.1.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#consistencia-1"><i class="fa fa-check"></i><b>4.1.2</b> Consistencia</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#cálculo-numérico"><i class="fa fa-check"></i><b>4.2</b> Cálculo numérico</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#método-de-los-momentos"><i class="fa fa-check"></i><b>4.2.1</b> Método de los momentos</a></li>
<li class="chapter" data-level="4.2.2" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#método-delta"><i class="fa fa-check"></i><b>4.2.2</b> Método Delta</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="estimación-por-máxima-verosimilitud.html"><a href="estimación-por-máxima-verosimilitud.html#laboratorio-1"><i class="fa fa-check"></i><b>4.3</b> Laboratorio</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html"><i class="fa fa-check"></i><b>5</b> Estadísticos Suficientes y Criterio de Factorización</a>
<ul>
<li class="chapter" data-level="5.1" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadísticos-suficientes"><i class="fa fa-check"></i><b>5.1</b> Estadísticos suficientes</a></li>
<li class="chapter" data-level="5.2" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#teorema-de-factorización-de-fisher"><i class="fa fa-check"></i><b>5.2</b> Teorema de Factorización de Fisher</a></li>
<li class="chapter" data-level="5.3" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadístico-suficiente-multivariado."><i class="fa fa-check"></i><b>5.3</b> Estadístico suficiente multivariado.</a></li>
<li class="chapter" data-level="5.4" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#estadísticos-minimales"><i class="fa fa-check"></i><b>5.4</b> Estadísticos minimales</a></li>
<li class="chapter" data-level="5.5" data-path="estadísticos-suficientes-y-criterio-de-factorización.html"><a href="estadísticos-suficientes-y-criterio-de-factorización.html#mejorando-estimadores"><i class="fa fa-check"></i><b>5.5</b> Mejorando estimadores</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html"><i class="fa fa-check"></i><b>6</b> Distribución muestral de un estadístico</a>
<ul>
<li class="chapter" data-level="6.1" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-muestral"><i class="fa fa-check"></i><b>6.1</b> Distribución muestral</a></li>
<li class="chapter" data-level="6.2" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-chi2"><i class="fa fa-check"></i><b>6.2</b> Distribución <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="6.3" data-path="distribución-muestral-de-un-estadístico.html"><a href="distribución-muestral-de-un-estadístico.html#distribución-t"><i class="fa fa-check"></i><b>6.3</b> Distribución <span class="math inline">\(t\)</span></a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>7</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="7.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-para-la-media-de-una-distribución-normal"><i class="fa fa-check"></i><b>7.1</b> Intervalos de confianza para la media de una distribución normal</a></li>
<li class="chapter" data-level="7.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-normal."><i class="fa fa-check"></i><b>7.2</b> Caso normal.</a></li>
<li class="chapter" data-level="7.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-abiertos"><i class="fa fa-check"></i><b>7.3</b> Intervalos de confianza abiertos</a></li>
<li class="chapter" data-level="7.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-en-otros-casos"><i class="fa fa-check"></i><b>7.4</b> Intervalos de confianza en otros casos</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalos-de-confianza-aproximados."><i class="fa fa-check"></i><b>7.4.1</b> Intervalos de confianza aproximados.</a></li>
<li class="chapter" data-level="7.4.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#transformaciones-estabilizadoras-de-la-varianza"><i class="fa fa-check"></i><b>7.4.2</b> Transformaciones estabilizadoras de la varianza</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html"><i class="fa fa-check"></i><b>8</b> Estimación Bayesiana bajo normalidad</a>
<ul>
<li class="chapter" data-level="8.1" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#precisión-de-una-distribución-normal"><i class="fa fa-check"></i><b>8.1</b> Precisión de una distribución normal</a></li>
<li class="chapter" data-level="8.2" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#distribución-marginal-de-mu"><i class="fa fa-check"></i><b>8.2</b> Distribución marginal de <span class="math inline">\(\mu\)</span></a></li>
<li class="chapter" data-level="8.3" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#intervalos-de-credibilidad."><i class="fa fa-check"></i><b>8.3</b> Intervalos de credibilidad.</a></li>
<li class="chapter" data-level="8.4" data-path="estimación-bayesiana-bajo-normalidad.html"><a href="estimación-bayesiana-bajo-normalidad.html#efecto-de-previas-no-informativas-opcional"><i class="fa fa-check"></i><b>8.4</b> Efecto de previas no informativas (Opcional)</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html"><i class="fa fa-check"></i><b>9</b> Estimación insesgada</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimadores-insesgados"><i class="fa fa-check"></i><b>9.1</b> Estimadores insesgados</a></li>
<li class="chapter" data-level="9.2" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimador-insesgado-de-la-varianza"><i class="fa fa-check"></i><b>9.2</b> Estimador insesgado de la varianza</a></li>
<li class="chapter" data-level="9.3" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#información-de-fisher"><i class="fa fa-check"></i><b>9.3</b> Información de Fisher</a></li>
<li class="chapter" data-level="9.4" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#desigualdad-de-cramer-rao"><i class="fa fa-check"></i><b>9.4</b> Desigualdad de Cramer-Rao</a></li>
<li class="chapter" data-level="9.5" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#estimadores-eficientes"><i class="fa fa-check"></i><b>9.5</b> Estimadores eficientes</a></li>
<li class="chapter" data-level="9.6" data-path="estimación-insesgada.html"><a href="estimación-insesgada.html#comportamiento-asintótico-del-mle"><i class="fa fa-check"></i><b>9.6</b> Comportamiento asintótico del MLE</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html"><i class="fa fa-check"></i><b>10</b> Pruebas de hipótesis</a>
<ul>
<li class="chapter" data-level="10.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-hipótesis-1"><i class="fa fa-check"></i><b>10.1</b> Pruebas de hipótesis</a></li>
<li class="chapter" data-level="10.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#regiones-críticas-y-estadísticas-de-prueba"><i class="fa fa-check"></i><b>10.2</b> Regiones críticas y estadísticas de prueba</a></li>
<li class="chapter" data-level="10.3" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#función-de-potencia-y-tipos-de-error"><i class="fa fa-check"></i><b>10.3</b> Función de potencia y tipos de error</a></li>
<li class="chapter" data-level="10.4" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#valor-p"><i class="fa fa-check"></i><b>10.4</b> Valor <span class="math inline">\(p\)</span></a></li>
<li class="chapter" data-level="10.5" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#dualidad-entre-pruebas-de-hipótesis-y-regiones-de-confianza"><i class="fa fa-check"></i><b>10.5</b> Dualidad entre pruebas de hipótesis y regiones de confianza</a>
<ul>
<li class="chapter" data-level="10.5.1" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#dualidad-en-pruebas-unilaterales"><i class="fa fa-check"></i><b>10.5.1</b> Dualidad en pruebas unilaterales</a></li>
<li class="chapter" data-level="10.5.2" data-path="pruebas-de-hipótesis.html"><a href="pruebas-de-hipótesis.html#pruebas-de-cociente-de-verosimilitud-lrt"><i class="fa fa-check"></i><b>10.5.2</b> Pruebas de cociente de verosimilitud (LRT)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html"><i class="fa fa-check"></i><b>11</b> Pruebas con hipótesis simples</a>
<ul>
<li class="chapter" data-level="11.1" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#hipótesis-simples"><i class="fa fa-check"></i><b>11.1</b> Hipótesis simples</a></li>
<li class="chapter" data-level="11.2" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#criterio-de-neyman-pearson"><i class="fa fa-check"></i><b>11.2</b> Criterio de Neyman-Pearson</a></li>
<li class="chapter" data-level="11.3" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#pruebas-insesgadas"><i class="fa fa-check"></i><b>11.3</b> Pruebas insesgadas</a></li>
<li class="chapter" data-level="11.4" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#prueba-t"><i class="fa fa-check"></i><b>11.4</b> Prueba <span class="math inline">\(t\)</span></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#propiedades-de-las-pruebas-t"><i class="fa fa-check"></i><b>11.4.1</b> Propiedades de las pruebas <span class="math inline">\(t\)</span></a></li>
<li class="chapter" data-level="11.4.2" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#prueba-t-pareada"><i class="fa fa-check"></i><b>11.4.2</b> Prueba <span class="math inline">\(t\)</span> pareada</a></li>
<li class="chapter" data-level="11.4.3" data-path="pruebas-con-hipótesis-simples.html"><a href="pruebas-con-hipótesis-simples.html#pruebas-t-de-dos-colas"><i class="fa fa-check"></i><b>11.4.3</b> Pruebas <span class="math inline">\(t\)</span> de dos colas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html"><i class="fa fa-check"></i><b>12</b> Prueba de comparación de medias en 2 poblaciones</a>
<ul>
<li class="chapter" data-level="12.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#comparación-de-medias-normales"><i class="fa fa-check"></i><b>12.1</b> Comparación de medias normales</a></li>
<li class="chapter" data-level="12.2" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-t-de-dos-muestras"><i class="fa fa-check"></i><b>12.2</b> Prueba <span class="math inline">\(t\)</span> de dos muestras</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-de-2-colas"><i class="fa fa-check"></i><b>12.2.1</b> Prueba de 2 colas</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-f"><i class="fa fa-check"></i><b>12.3</b> Prueba <span class="math inline">\(F\)</span></a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="prueba-de-comparación-de-medias-en-2-poblaciones.html"><a href="prueba-de-comparación-de-medias-en-2-poblaciones.html#prueba-de-2-colas-prueba-de-homocedasticidad"><i class="fa fa-check"></i><b>12.3.1</b> Prueba de 2 colas (prueba de homocedasticidad)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pruebas-de-hipótesis-bayesianas.html"><a href="pruebas-de-hipótesis-bayesianas.html"><i class="fa fa-check"></i><b>13</b> Pruebas de hipótesis bayesianas</a>
<ul>
<li class="chapter" data-level="13.1" data-path="pruebas-de-hipótesis-bayesianas.html"><a href="pruebas-de-hipótesis-bayesianas.html#pruebas-de-hipótesis-bayesianas-1"><i class="fa fa-check"></i><b>13.1</b> Pruebas de hipótesis bayesianas</a></li>
<li class="chapter" data-level="13.2" data-path="pruebas-de-hipótesis-bayesianas.html"><a href="pruebas-de-hipótesis-bayesianas.html#hipótesis-de-una-cola"><i class="fa fa-check"></i><b>13.2</b> Hipótesis de una cola</a></li>
<li class="chapter" data-level="13.3" data-path="pruebas-de-hipótesis-bayesianas.html"><a href="pruebas-de-hipótesis-bayesianas.html#hipótesis-de-2-colas"><i class="fa fa-check"></i><b>13.3</b> Hipótesis de 2 colas</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html"><i class="fa fa-check"></i><b>14</b> Bondad de ajuste</a>
<ul>
<li class="chapter" data-level="14.1" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html#prueba-chi2"><i class="fa fa-check"></i><b>14.1</b> Prueba <span class="math inline">\(\chi^2\)</span></a></li>
<li class="chapter" data-level="14.2" data-path="bondad-de-ajuste.html"><a href="bondad-de-ajuste.html#pruebas-chi2-con-hipótesis-parametrizadas"><i class="fa fa-check"></i><b>14.2</b> Pruebas <span class="math inline">\(\chi^2\)</span> con hipótesis parametrizadas</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html"><i class="fa fa-check"></i><b>15</b> Tablas de contingencia</a>
<ul>
<li class="chapter" data-level="15.1" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#hipótesis-de-independencia"><i class="fa fa-check"></i><b>15.1</b> Hipótesis de independencia</a></li>
<li class="chapter" data-level="15.2" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#prueba-de-homogeneidad"><i class="fa fa-check"></i><b>15.2</b> Prueba de homogeneidad</a></li>
<li class="chapter" data-level="15.3" data-path="tablas-de-contingencia.html"><a href="tablas-de-contingencia.html#comparación-de-proporciones"><i class="fa fa-check"></i><b>15.3</b> Comparación de proporciones</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html"><i class="fa fa-check"></i><b>16</b> Ejercicios varios</a>
<ul>
<li class="chapter" data-level="16.1" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html#capítulo-8"><i class="fa fa-check"></i><b>16.1</b> Capítulo 8</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="ejercicios-varios.html"><a href="ejercicios-varios.html#section"><i class="fa fa-check"></i><b>16.1.1</b> 8.4.6</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notas Curso de Estadística (Parte I)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="pruebas-de-hipótesis-bayesianas" class="section level1" number="13">
<h1><span class="header-section-number">Capítulo 13</span> Pruebas de hipótesis bayesianas</h1>
<div id="pruebas-de-hipótesis-bayesianas-1" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Pruebas de hipótesis bayesianas</h2>
<p>Suponga que <span class="math inline">\(\Omega = \{\theta_0,\theta_1\}\)</span>. Si <span class="math inline">\(\theta = \theta_i\)</span>
<span class="math inline">\((i = 0,1)\)</span>, <span class="math inline">\(X_1,\dots, X_n\sim f_i(x)\)</span>. Considere las hipótesis</p>
<p><span class="math display">\[H_0: \theta = \theta_0 \text{ vs } H_1: \theta =\theta_1.\]</span></p>
<p>Hay dos decisiones, <span class="math inline">\(d_0:\)</span> no rechazo <span class="math inline">\(H_0\)</span> y <span class="math inline">\(d_1:\)</span> rechazo <span class="math inline">\(H_0\)</span>.</p>
<p>Asuma que si selecciono <span class="math inline">\(d_1\)</span> cuando <span class="math inline">\(H_0\)</span> es cierto, la pérdida es <span class="math inline">\(w_0\)</span>
unidades. Por
el contrario, si selecciono <span class="math inline">\(d_1\)</span> cuando <span class="math inline">\(H_0\)</span> es cierto, la pérdida es <span class="math inline">\(w_1\)</span>
unidades.</p>
<p>Como un ejemplo, se podría pensar <span class="math inline">\(w_0\)</span> y <span class="math inline">\(w_1\)</span> como la pérdida en colones
que ocurre cuando me equivoco al tomar una desición errónea.</p>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(d_0\)</span></th>
<th><span class="math inline">\(d_1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\theta_0\)</span></td>
<td>0</td>
<td><span class="math inline">\(w_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\theta_1\)</span></td>
<td><span class="math inline">\(w_1\)</span></td>
<td>0</td>
</tr>
</tbody>
</table>
<p><strong>Ejemplo:</strong> Recuerden el ejemplo del administrador del  que
tenía que decidir si <span class="math inline">\(f_0\)</span> o <span class="math inline">\(f_1\)</span> era la distribución correcta para la
entrada de llamadas. El administrador observa lo siguiente: <span class="math inline">\(f_1\)</span> asigna más
probabilidad a los tiempos de llamadas largos y extremadamente pequeños con
respecto a <span class="math inline">\(f_0\)</span>.</p>
<p>Suponga que el costo de modelar tiempos de servicio extremadamente grandes como
menos probables de lo que realmente son es el mismo que el costo de modelar
tiempos de servicio extremadamente grandes para que sean más probables de lo que
realmente son.</p>
<p>Entonces el administrador concluye que no hay diferencia en el costo si el se
escoge la distribución incorrecta para modelar el tiempo, de modo que la pérdida
para la empresa es <span class="math inline">\(w_0=w_1\)</span> colones independientemente de la escogencia.
<span class="math inline">\(\hfill\blacktriangleleft\)</span></p>
<p>Defina las distribuciones previas <span class="math inline">\(\pi_0 = \mathbb P[H_0 \text{ es cierta}]  = \mathbb P[H_0]\)</span> y <span class="math inline">\(\pi_1 = \mathbb P[H_1 \text{ es cierta}] = 1 -\mathbb  P[H_0]\)</span>.</p>
<p><strong>Ejemplo:</strong> Para el caso del <em>call center</em> suponga que el administrador asigna
igual probabilidad de equivocarse, por lo tanto define <span class="math inline">\(\pi_0=\pi_1 = 1/2\)</span>.</p>
<p>Recuerden que <span class="math inline">\(\delta\)</span> es la regla de decisión de la prueba. El valor esperado
de la pérdida corresponde a</p>
<p><span class="math display">\[ r(\delta) = \mathbb E[\text{Pérdida}|H_0] \mathbb P[H_0] + \mathbb
    E[\text{Pérdida}|H_1]\mathbb P[H_1].\]</span></p>
<p>Asumiendo que <span class="math inline">\(H_0\)</span> es cierto,</p>
<p><span class="math display">\[\begin{align*}
    \mathbb E[\text{Pérdida}|H_0] &amp; = w_0\cdot \mathbb
    P[\text{Seleccione } d_1|\theta_0] + 0\cdot \mathbb P[\text{Seleccione }
    d_0|\theta_0]                                      \\ 
    &amp; = w_0 \cdot \text{Error Tipo I} = w_0\ \alpha(\delta).
\end{align*}\]</span>
Por el otro lado,</p>
<p><span class="math display">\[\begin{align*}
    \mathbb E[\text{Pérdida}|H_1] &amp; = 0\cdot \mathbb P[\text{Seleccione } d_1|\theta_0] + w_1\cdot \mathbb P[\text{Seleccione } d_0|\theta_0] \\
&amp; = w_1 \cdot \text{Error Tipo II} = w_1\ \beta(\delta).
\end{align*}\]</span></p>
<p>Entonces <span class="math inline">\(r(\delta) = w_0\alpha(\delta) + w_1\beta(\delta)\)</span>.</p>
<p>El objetivo siempre será minimizar <span class="math inline">\(r(\delta)\)</span> ya que sería la pérdida
total. A esta minimización es el procedimiento de prueba bayesiana.</p>
<p>Por el teorema de Neyman-Pearson y tomando <span class="math inline">\(a=\pi_0w_0\)</span> y <span class="math inline">\(b=\pi_1w_1\)</span>, la regla
de decisión <span class="math inline">\(\delta\)</span> que soluciona el problema es:</p>
<p><span class="math display">\[\begin{align*}
\text{Rechazo }H_0 \text{ si } 
&amp; \pi_0w_0f_0(x) \leq \pi_1w_1f_1(x). \\
&amp; \dfrac{f_1(x)}{f_0(x)} \geq \dfrac{\pi_0w_0}{\pi_1w_1} \\
&amp; \dfrac{f_1(x)}{f_0(x)} \geq \dfrac{a}{b} \\
&amp; \dfrac{f_1(x)}{f_0(x)} \geq k \\
\end{align*}\]</span></p>
<p><strong>Nota</strong>. La decisión <span class="math inline">\(\delta\)</span> es invariante a multiplicaciones por escalar en el
costo.</p>
<!-- Recordemos como estimar la distribuciones posteriores en el caso bayesiano -->
<!-- \[\pi(\theta_0|x) = \dfrac{\pi_0f_0(x)}{\pi_0f_0(x)+\pi_1f_1(x)}\] -->
<!-- \[\pi(\theta_1|x) = \dfrac{\pi_1f_1(x)}{\pi_0f_0(x)+\pi_1f_1(x)}\] -->
<!-- En este casos la esperanza de la pérdida se calcula como:  -->
<!-- \[\mathbb E[\text{Pérdida}|x] = \mathbb E[\text{Pérdida}|\theta_0,x] + \mathbb E[\text{Pérdida}|\theta_1,x].\] -->
<!-- Si escogemos  esta decisión obtenemos que  $\delta = d_0$, -->
<!-- \[\mathbb E_\delta[\text{Pérdida}|X] = w_1\pi(\theta_1|x) = \dfrac{w_1\pi_1f_1(x)}{\pi_0f_0(x)+\pi_1f_1(x)}. \] -->
<!-- En el otro caso obtenemos que  $\delta = d_1$, -->
<!-- \[\mathbb E_\delta[\text{Pérdida}|X] = \dfrac{w_0\pi_0f_0(x)}{\pi_0f_0(x)+\pi_1f_1(x)}. \] -->
<!-- Minimizar $\mathbb E[\text{Pérdida}|x]$ con respecto a $\delta$ es equivalente a -->
<!-- rechazar $H_0$ bajo el criterio anterior. -->
<!-- **Conclusión**: es equivalente construir la decisión en cualquiera de los dos -->
<!-- criterios (previa o probabilidad posterior). -->
<!-- c. Rechazo $H_0$ si -->
<!-- $\mathbb P[H_0 \text{ es cierto}|X] \leq \dfrac{w_1}{w_0+w_1}.$ -->
<!-- Rechazamos $H_0$ si -->
<!-- \[\dfrac{w_0\pi_0f_0(x)}{\pi_0f_0(x)+\pi_1f_1(x)}\leq \dfrac{w_1\pi_1f_1(x)}{\pi_0f_0(x)+\pi_1f_1(x)}.\] -->
<!-- Rechazamos $H_0$ si  -->
<!-- \begin{align*} -->
<!-- \dfrac{w_0\pi_0f_0(x)}{\pi_0f_0(x)+\pi_1f_1(x)}  -->
<!-- & \leq \dfrac{w_1\pi_1f_1(x)}{\pi_0f_0(x)+\pi_1f_1(x)} \\ -->
<!-- w_0\pi_0f_0(x)   -->
<!-- & \leq w_1\pi_1f_1(x) \\ -->
<!-- \dfrac{w_0\pi_0}{w_1\pi_1} &\leq \dfrac{f_1(x)}{f_0(x)} -->
<!-- \end{align*} -->
<!-- Entonces -->
<!-- \[w_0\mathbb P[H_0|x] \leq w_1\mathbb P[H_1|x] = w_1[1-\mathbb P[H_0|x]] -->
<!-- \implies\mathbb P[H_0|x]\leq \dfrac{w_1}{w_0+w_1}. \] -->
<p><strong>Ejemplo:</strong> En el ejemplo del <em>call center</em> con las condiciones planteadas la
regla de decisión bayesiana sería</p>
<p><span class="math display">\[\begin{align*}
\dfrac{w_0\pi_0}{w_1\pi_1} &amp;\leq \dfrac{f_1(x)}{f_0(x)} \\
1 &amp;\leq \dfrac{f_1(x)}{f_0(x)} \\
\end{align*}\]</span></p>
</div>
<div id="hipótesis-de-una-cola" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Hipótesis de una cola</h2>
<p><em>Caso general</em>: <span class="math inline">\(H_0: \theta \in \Omega_0\)</span> vs <span class="math inline">\(H_1: \theta \in \Omega_1\)</span>.
Asuma la misma función de pérdida <span class="math inline">\(L(\theta,d_i)\)</span>:</p>
<table>
<thead>
<tr class="header">
<th></th>
<th><span class="math inline">\(d_0\)</span></th>
<th><span class="math inline">\(d_1\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(H_0\)</span></td>
<td>0</td>
<td><span class="math inline">\(w_0\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(H_1\)</span></td>
<td><span class="math inline">\(&amp;w_1\)</span></td>
<td>0</td>
</tr>
</tbody>
</table>
<p>y considere la hipótesis <span class="math inline">\(H_0: \theta \leq \theta_0\)</span> vs <span class="math inline">\(H_1: \theta &gt; \theta_0\)</span>.</p>
<p><strong>Teorema</strong>. Suponga que <span class="math inline">\(f_n(x|\theta)\)</span> tiene un cociente de verosimilitud
monótono con respecto al estadístico <span class="math inline">\(T=r(x)\)</span>. Es decir, <span class="math inline">\(R(x) =  \dfrac{f_n(x|\theta_1)}{f_n(x|\theta_0)} = g(r(x))\)</span> con <span class="math inline">\(g(r(x))\)</span> monótono con
respecto a <span class="math inline">\(r(x)\)</span>.</p>
<p>Asuma la función de pérdida anterior. Entonces el procedimiento bayesiano de
prueba rechaza <span class="math inline">\(H_0\)</span> cuando <span class="math inline">\(T\geq c\)</span>.</p>
<p><strong>Definición</strong>. Si <span class="math inline">\(f_n(x|\theta)\)</span> es una verosimilitud y <span class="math inline">\(T=r(x)\)</span> un
estadístico, decimos que <span class="math inline">\(f_n(x|\theta)\)</span> tiene un MLR con respecto a <span class="math inline">\(T\)</span> si para
<span class="math inline">\(\theta_1,\theta_2 \in \Omega\)</span> tales que <span class="math inline">\(\theta_1 &lt;\theta_2\)</span>,
<span class="math inline">\(\dfrac{f_n(x|\theta_2)}{f_n(x|\theta_1)}\)</span> depende de <span class="math inline">\(x\)</span> a través de <span class="math inline">\(r(x)\)</span> y
es una función monótona de <span class="math inline">\(r(x)\)</span>.</p>
<p><strong>Ejemplo</strong>. <span class="math inline">\(X_1,\dots, X_n \sim N(\mu,\sigma^2)\)</span>, <span class="math inline">\(\sigma^2\)</span> conocido. Si
<span class="math inline">\(\mu_1&lt;\mu_2\)</span>:</p>
<p><span class="math display">\[\begin{align*}
    \dfrac{f_n(x|\mu_2)}{f_n(x|\mu_1)} &amp; =
    \dfrac{(2\pi\sigma^2)^{-n/2}\exp\bigg[-\dfrac 1{2\sigma^2}\sum
            (X_i-\mu_2)^2\bigg]}{(2\pi\sigma^2)^{-n/2}\exp\bigg[-\dfrac 1{2\sigma^2}\sum
    (X_i-\mu_1)^2\bigg]}                   \\ &amp; = \exp\bigg[\dfrac{n(\mu_2-\mu_1)}{\sigma^2}\bar X_n
        -\dfrac 12 (\mu_2+\mu_1))\bigg] = g(T)
\end{align*}\]</span></p>
<p>Entonces <span class="math inline">\(g(T)\)</span> es monótono creciente con respecto a <span class="math inline">\(T=\bar X_n\)</span> y por lo tanto
tiene un MLE con respecto a <span class="math inline">\(\bar X_n\)</span>.</p>
<p><em>Prueba</em>. Recuerde que</p>
<p><span class="math display">\[\pi(\theta|x) = \dfrac{f_n(x|\theta)\pi(\theta)}{\int f_n(x|\psi)\pi(\psi)d\psi}\]</span></p>
<p><span class="math display">\[\begin{align*}
    \mathcal L(x) = \dfrac{\mathbb E[\text{Pérdida}|x,d_0]}{\mathbb E[\text{Pérdida}|x,d_1]} &amp; = \dfrac{\dfrac 1{\text{cte}} \displaystyle\int_{\theta_0}^\infty w_1f_n(x|\theta)\pi(\theta)d\theta}{\dfrac 1{\text{cte}} \displaystyle\int_{-\infty}^{\theta_0} w_0f_n(x|\theta)\pi(\theta)d\theta} \\ &amp; = \dfrac{w_1}{w_0}\dfrac{ \displaystyle\int_{\theta_0}^\infty f_n(x|\theta)\pi(\theta)d\theta}{ \displaystyle\int_{-\infty}^{\theta_0} f_n(x|\theta)\pi(\theta)d\theta}  \geq 1
\end{align*}\]</span></p>
<p>Buscamos rechazar si <span class="math inline">\(l(x)\geq 1\)</span> (prueba bayesiana) y si existe una función
monótona tal que <span class="math inline">\(l(x)\geq 1 \Leftrightarrow T\geq c\)</span>, entonces ambas pruebas
son iguales. Basta con probar que <span class="math inline">\(l(x)\)</span> es una función monótona creciente de
<span class="math inline">\(T\)</span>.</p>
<p>Sea <span class="math inline">\(X_1,X_2\in \mathcal X\)</span> tal que <span class="math inline">\(r(X_1)\leq r(X_2)\)</span>. Entonces</p>
<p><span class="math display">\[ l(X_1)-l(X_2) = \dfrac{w_1 \displaystyle\int_{\theta_0}^\infty f_n(x_1|\theta)\pi(\theta)d\theta}{w_0 \displaystyle\int_{-\infty}^{\theta_0} f_n(x_1|\theta)\pi(\theta)d\theta} -\dfrac{w_1 \displaystyle\int_{\theta_0}^\infty f_n(x_2|\theta)\pi(\theta)d\theta}{w_0 \displaystyle\int_{-\infty}^{\theta_0} f_n(x_2|\theta)\pi(\theta)d\theta}\leq 0. \]</span></p>
<p>Si simplificamos la expresión en una sola fracción, el numerador es de la forma</p>
<p><span class="math display">\[\int_{\theta_0}^\infty\int_{-\infty}^{\theta_0}\pi(\theta)\pi(\psi)[f_n(x_1|\theta)f_n(x_2|\psi)-f_n(x_2|\theta)f_n(x_1|\psi)]\;d\psi
  d\theta\]</span></p>
<p>y el denominador es siempre positivo, por lo que basta con que el numerador sea
negativo.</p>
<p>Como <span class="math inline">\(f_n(x|\theta)\)</span> tiene un MLR, si <span class="math inline">\(r(x_1)\leq r(x_2)\)</span> y
<span class="math inline">\(-\infty &lt;\psi\leq \theta_0\leq \theta&lt;+\infty\)</span>,
<span class="math display">\[\dfrac{f_n(x_1|\theta)}{f_n(x_1|\psi)}\leq\dfrac{f_n(x_2|\theta)}{f_n(x_2|\psi)} \Leftrightarrow f_n(x_1|\theta)f_n(x_2|\psi)\leq f_n(x_2|\theta)f_n(x_1|\psi) \]</span></p>
<p>Entonces <span class="math inline">\(l(x_1)\leq l(x_2)\)</span> y por tanto ambas pruebas son equivalentes.</p>
<p><strong>Ejemplo</strong>. Diferencias porcentuales entre calorías observadas y calorías en
publicidad para 20 productos preparados.</p>
<p><span class="math inline">\(X_1,\dots,X_{20}\sim N(\theta,100)\)</span>, <span class="math inline">\(\theta\sim N(0,60)\)</span></p>
<p>La media posterior es</p>
<p><span class="math display">\[\dfrac{100\cdot 0 + 20\cdot 60\bar X_{20}}{100+20\cdot 60} = 0.923\bar
X_{20}.\]</span></p>
<p>y <span class="math inline">\(\sigma_1^2 = 4.62\)</span>.</p>
<p>La hipótesis de interés es <span class="math inline">\(H_0:\theta\leq 0\)</span> vs <span class="math inline">\(H_1:\theta&gt;0\)</span>.</p>
<p><span class="math inline">\(\delta\)</span>: Rechazo <span class="math inline">\(H_0\)</span> si <span class="math inline">\(\mathbb P[H_0|\bar X_{20}]\leq \dfrac{w_1}{w_0+w_1}\)</span>, donde</p>
<p><span class="math display">\[\mathbb P[\theta\leq 0|\bar X_{20}] = \mathbb P\bigg[Z\bigg|\dfrac{-0.923\bar
X_{20}}{4.62}\bigg] = \Phi(-0.429\bar X_{20}).\]</span></p>
<p>Bajo <span class="math inline">\(\delta\)</span>:</p>
<p><span class="math display">\[\begin{align*} 
\Phi(-0.429\bar X_{20})\leq \dfrac{w_1}{w_0+w_1}=\beta &amp; \implies
    -0.429\bar X_{20}\leq \Phi^{-1}(\beta) \\ &amp; \implies \bar X_{20} \geq
    \dfrac{-\Phi^{-1}(\beta)}{0.429} 
\end{align*}\]</span></p>
<p>Si <span class="math inline">\(w_0 = w_1 \implies \beta = 1/2\)</span> y <span class="math inline">\(\Phi(1/2) =0\)</span>. Por lo tanto <span class="math inline">\(\bar X_{20}\geq 0\)</span>.</p>
<p><strong>Interpretación</strong>. Si <span class="math inline">\(\bar X_{20}\geq c\)</span> entonces aceptamos la hipótesis de
que <span class="math inline">\(\theta&gt;0\)</span> (en términos de la aplicación).</p>
</div>
<div id="hipótesis-de-2-colas" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Hipótesis de 2 colas</h2>
<p><span class="math display">\[H_0: \theta = \theta_0 \text{ vs } H_1:\theta \ne \theta_0\]</span></p>
<p>La significancia práctica indica que “ser igual a <span class="math inline">\(\theta_0\)</span> significa estar
cerca”.</p>
<p>Replanteamos <span class="math inline">\(H_0\)</span>, tomando <span class="math inline">\(d&gt;0\)</span>:
<span class="math display">\[H_0: |\theta-\theta_0|\leq d \text{ vs } H_1: |\theta-\theta_0|&gt;d.\]</span></p>
<p>En el ejemplo anterior, <span class="math inline">\((\theta_0 = 0)\)</span></p>
<p><span class="math display">\[\mathbb P[H_0|\bar X_{20}]=\mathbb P[|\theta|\leq d|\bar X_{20}] =
\Phi\left(\dfrac{d-0.1154}{4.62^{1/2}}\right) -
\Phi\left(\dfrac{-d-0.1154}{4.62^{1/2}}\right) = g(d)\]</span></p>
<p>En el caso normal, si <span class="math inline">\(X_1,\dots,X_n\sim N(\mu,\sigma^2)\)</span> ambos parámetros
desconocidos y <span class="math inline">\(\tau = \dfrac 1{\sigma^2}\)</span>, recuerde que</p>
<p><span class="math display">\[[\mu,\tau]\sim \text{Normal-Gamma}(\mu_0,\lambda_0,\alpha_0,\beta_0)\implies
\left(\dfrac{\lambda_0\alpha_0}{\beta_0}\right)^{\frac 12}(\mu-\mu_0)\sim
t_{2\alpha_0}\]</span></p>
<p>y la marginal de <span class="math inline">\(\mu\)</span> se usa en el cálculo <span class="math inline">\(\mathbb P[H_0|x]\)</span>.</p>
<p><strong>Ejemplo</strong>. Residuos de un pesticida en apio. <span class="math inline">\(X_1,\dots, X_{77}\sim N(\mu,\sigma^2)\)</span>. Usamos una previa impropia de <span class="math inline">\((\mu,\sigma^2)\)</span>,</p>
<p><span class="math display">\[\pi(\mu,\tau)\propto \tau^{-1}\]</span>.</p>
<p>Recuerde, además, que</p>
<p><span class="math display">\[U = \left(\dfrac{n(n-1)}{s_n^2}\right)^{\frac 12}(\mu-\bar X_n)\sim t_{n-1}\]</span>
en el nivel posterior.</p>
<p>Nos interesa probar <span class="math inline">\(H_0: \mu\geq 55\)</span> vs <span class="math inline">\(H_1:\mu&lt;55\)</span>.</p>
<p>Los datos son <span class="math inline">\(\bar X_{77} = 50.23\)</span>, <span class="math inline">\(s_{77}^2=34106\)</span>.</p>
<p><span class="math display">\[\begin{align*}
    \mathbb P[H_0|X] &amp; = \mathbb P[\mu\geq 55|X] \\ &amp; = \mathbb
     P\left[\dfrac{\mu-\bar
     X_{77}}{\left(\frac{\sigma_2&#39;}{77}\right)^{1/2}}\right] \leq \mathbb
     P\left[\dfrac{55-50.23}{\left(\frac{\sigma_2&#39;}{77}\right)^{1/2}}\right] \\
     &amp; = 1-T_{76}[1.974] = 0.026
\end{align*}\]</span></p>
<p>Note que
<span class="math inline">\(\dfrac{-\bar X_{77}-\overbrace{55}^{\mu_0} }{\left(\frac{\sigma_2&#39;}{77}\right)^{1/2}} = -U\)</span></p>
<p>donde <span class="math inline">\(U\)</span> es el estadístico de prueba en el caso frecuentista y</p>
<p><span class="math display">\[\mathbb P[H_0|X] = \mathbb P[\underbrace{t_{n-1}\geq -\overbrace{u}^{\text{Observado}}}_{\text{Región de rechazo}\\\text{en la prueba frecuentista}}|X]\leq \alpha_0\]</span></p>
<p><em>Interpretación</em>: aceptamos la hipótesis de que el valor medio del pesticida es
menor o igual a 55 ante una función de pérdida en donde <span class="math inline">\(w_0 = w_1\)</span>.</p>
<p><strong>Teorema</strong>. Sean <span class="math inline">\(X_1,\dots,X_m\sim N(\mu_1,\tau)\)</span> y
<span class="math inline">\(Y_1,\dots, Y_n\sim N(\mu_2,\tau)\)</span> dos muestras y
<span class="math inline">\(\pi(\mu_1,\mu_2,\tau)\propto \tau^{-1}\)</span>, <span class="math inline">\(\tau &gt; 0\)</span>. Entonces
<span class="math display">\[(m+n-2)^{1/2}\dfrac{\mu_1-\mu_2-(\bar X_{m}-\bar Y_n)}{\left(\dfrac 1m + \dfrac 1n\right)^{1/2}(s_X^2+s_Y^2)^{1/2}}\sim t_{m+n-2}\]</span>
condicionado en <span class="math inline">\((X,Y)\)</span>.</p>
<p><em>Prueba</em>: Ejercicio.</p>
<p><strong>Consecuencia</strong>. Si queremos probar <span class="math inline">\(H_0: \mu_1-\mu_2\leq 0\)</span> vs
<span class="math inline">\(H_1:\mu_1-\mu_2&gt;0\)</span>, <span class="math display">\[\mathbb P[\mu_1-\mu_2\leq 0|x,y] = \mathbb
P\left[t_{m+n-2}\leq \dfrac{-(\bar X_m-\bar Y_n)}{\left(\dfrac 1m + \dfrac
1n\right)^{1/2}(s_X^2+s_Y^2)^{1/2}}(m+n-2)^{1/2}\right] = T_{m+n-2})(-u).\]</span></p>
<p>donde <span class="math inline">\(u\)</span> es el valor observado de la prueba de 2 muestras en el caso
frecuentista.</p>
<p>Rechazamos <span class="math inline">\(H_0\)</span> si</p>
<p><span class="math display">\[ T_{m+n-2}(-u)\leq \dfrac{w_1}{w_0+w_1}=\alpha_0 \Leftrightarrow -u\leq T_{m+n-2}^{-1}(\alpha_0) \implies u\geq -T_{m+n-2}^{-1}(\alpha_0) = T_{m+n-2}^{-1}(1-\alpha_0)\]</span></p>
<p>Es la misma prueba con <span class="math inline">\(\alpha_0 = \dfrac{w_1}{w_0+w_1}\)</span> con distinta
interpretación.</p>
<p>Otro caso particular es la prueba de varianzas en el caso normal con previas
impropias.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="prueba-de-comparación-de-medias-en-2-poblaciones.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bondad-de-ajuste.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica-parte-1/edit/master/12-hipotesis-bayesianas.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/maikol-solis/notas-curso-estadistica-parte-1/blob/master/12-hipotesis-bayesianas.Rmd",
"text": null
},
"download": ["Notas-Curso-Estadistica.pdf"],
"toc": {
"collapse": "subsection"
},
"toc_depth": 5
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
